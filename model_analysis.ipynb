{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timmonkey/Desktop/Imperial/Spring Term/Natural Language Processing/Coursework/nlp_classification/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertModel\n",
    "from torch.nn.functional import mse_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dev = Dataset.load_from_disk(\"data/dev\")\n",
    "dev_df = pd.DataFrame(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TODO COPY AND PASTE MAIN MODEL HERE #######\n",
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, transformer_out=6, dropout=0.1, class_weights=None):\n",
    "        super(CustomBert, self).__init__()\n",
    "        # Instead of just using the output of the final hidden layer,\n",
    "        # you can also pass in a range of hidden layers to concatenate their outputs\n",
    "        self.transformer_out = (\n",
    "            range(transformer_out, transformer_out + 1)\n",
    "            if isinstance(transformer_out, int)\n",
    "            else transformer_out\n",
    "        )\n",
    "        out_dim = len(self.transformer_out) * 768\n",
    "\n",
    "        # Use pretrained DistilBert. Force it to use our dropout\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\n",
    "            \"distilbert-base-uncased\", output_hidden_states=True\n",
    "        )  # type: DistilBertModel\n",
    "        for module in self.distilbert.modules():\n",
    "            if isinstance(module, torch.nn.Dropout):\n",
    "                module.p = dropout\n",
    "\n",
    "        # Then apply a dense hidden layer down to 768, and a final layer down to 1\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(out_dim, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(768, 1),\n",
    "        )\n",
    "\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = class_weights\n",
    "            self.pos_weight = class_weights[1] / class_weights[0]\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Recommended pooling approach for DistilBert is to average over the hidden state sequence\n",
    "        # instead of outputs.last_hidden_state[:, 0], which is used for Bert which uses [CLS] token\n",
    "        pooled_output = []\n",
    "        for i in self.transformer_out:\n",
    "            hs = outputs.hidden_states[i]\n",
    "            mask = attention_mask.unsqueeze(-1)\n",
    "            hs = hs * mask\n",
    "            mean_hs = hs.sum(dim=1) / mask.sum(dim=1)\n",
    "            pooled_output.append(mean_hs)\n",
    "\n",
    "        # We also concatenate the outputs of multiple layers if chosen by the user\n",
    "        cat_output = torch.cat(pooled_output, dim=1)\n",
    "\n",
    "        # Apply dense feedforward\n",
    "        y = self.feedforward(cat_output).squeeze(-1)\n",
    "\n",
    "        # Outside the Trainer, we return the predictions\n",
    "        if labels is None:\n",
    "            return y\n",
    "\n",
    "        # Inside the Trainer, we also need to return the loss\n",
    "        global binary_classifier\n",
    "        if binary_classifier:\n",
    "            loss = F.binary_cross_entropy_with_logits(\n",
    "                y, labels, pos_weight=self.pos_weight\n",
    "            ).to(DEVICE)\n",
    "        else:\n",
    "            loss = mse_loss(y, labels, reduction=\"none\").to(DEVICE)\n",
    "            weights = self.class_weights[labels.long().to(DEVICE)]\n",
    "            loss = loss * weights\n",
    "            loss = loss.mean()\n",
    "        return loss, y\n",
    "\n",
    "    def freeze(self):\n",
    "        for param in self.distilbert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze(self, layer=None):\n",
    "        for name, param in self.distilbert.named_parameters():\n",
    "            if layer is None or name.startswith(f\"transformer.layer.{layer}\"):\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBert(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feedforward): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomBert() # instantiate model\n",
    "\n",
    "# load in trained parameters\n",
    "checkpoint_fp = 'results/model.pth'\n",
    "checkpoint = torch.load(checkpoint_fp)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_by_group(group_df):\n",
    "    atten_masks = torch.LongTensor([ls for ls in group_df.attention_mask.values])\n",
    "    input_ids = torch.LongTensor([ls for ls in group_df.input_ids.values])\n",
    "    predictions = model(input_ids, atten_masks).detach().numpy() > 1.5 # NOTE this line makes kernel crash\n",
    "    return np.sum(predictions == group_df['pcl']) / len(group_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance by the Degree of PCL (Question 3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions and evaluate performance based on the degree of pcl\n",
    "pcl_levels = dev_df['labels'].unique()\n",
    "\n",
    "accuracy_by_pcl_level = []\n",
    "for pcl_level in pcl_levels:\n",
    "    dev_df_subset = dev_df[dev_df['labels'] == pcl_level]\n",
    "    accuracy = accuracy_by_group(dev_df_subset)\n",
    "    accuracy_by_pcl_level.append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(pcl_levels, accuracy_by_pcl_level)\n",
    "\n",
    "plt.xlabel(\"PCL Level\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance by Length of Sequence (Question 3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accuracy_by_len(df):\n",
    "    all_text_len = sorted(df.text.apply(len).unique())\n",
    "\n",
    "    accuracy_by_len = []\n",
    "    for text_len in all_text_len:\n",
    "        dev_df_subset = df[df['text'].apply(len) == text_len]\n",
    "        accuracy = accuracy_by_group(dev_df_subset)\n",
    "        accuracy_by_len.append(accuracy)\n",
    "    return all_text_len, accuracy_by_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions and evaluate performance based on the length of sequence\n",
    "all_text_len, accuracy_by_len = generate_accuracy_by_len(dev_df)\n",
    "pos_text_len, pos_accuracy_by_len = generate_accuracy_by_len(dev_df[dev_df['pcl'] == 1])\n",
    "neg_text_len, neg_accuracy_by_len = generate_accuracy_by_len(dev_df[dev_df['pcl'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_text_len, accuracy_by_len, label='All Samples')\n",
    "plt.plot(pos_text_len, pos_accuracy_by_len, label='Positive Samples')\n",
    "plt.plot(neg_text_len, neg_accuracy_by_len, label='Negative Samples')\n",
    "\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance by Keyword Category (Question 3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accuracy_by_keyword(df):\n",
    "    keywords = sorted(df['keyword'].unique())\n",
    "\n",
    "    accuracy_by_keyword = []\n",
    "    for keyword in keywords:\n",
    "        dev_df_subset = df[df['keyword'] == keyword]\n",
    "        accuracy = accuracy_by_group(dev_df_subset)\n",
    "        accuracy_by_keyword.append(accuracy)\n",
    "    return keywords, accuracy_by_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions and evaluate performance based on the keyword\n",
    "all_keywords, accuracy_by_keyword = generate_accuracy_by_keyword(dev_df)\n",
    "pos_keywords, pos_accuracy_by_keyword = generate_accuracy_by_keyword(dev_df[dev_df['pcl'] == 1])\n",
    "neg_keywords, neg_accuracy_by_keyword = generate_accuracy_by_keyword(dev_df[dev_df['pcl'] == 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "x_axis = np.arange(len(all_keywords))\n",
    "\n",
    "plt.bar(x_axis, accuracy_by_keyword, width=0.25, label='All Samples')\n",
    "plt.bar(x_axis + width, pos_accuracy_by_keyword, width=0.25, label='Positive Samples')\n",
    "plt.bar(x_axis + width*2, neg_accuracy_by_keyword, width=0.25, label='Negative Samples')\n",
    "\n",
    "plt.xlabel(\"Keyword\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "\n",
    "plt.xticks(x_axis+width, all_keywords) \n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
